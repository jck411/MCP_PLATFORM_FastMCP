# MCP Chatbot Configuration

# WebSocket Chat Configuration
chat:
  # WebSocket server configuration
  websocket:
    host: "localhost"
    port: 8000
    endpoint: "/ws/chat"

    # CORS settings
    allow_origins: ["*"]
    allow_credentials: true

    # WebSocket settings
    max_message_size: 16777216  # 16MB
    ping_interval: 20
    ping_timeout: 10

  # Chat Service Configuration
  service:
    # System prompt configuration
    system_prompt: |
      You are a helpful assistant with a sense of humor.
      You have access to to a list of tools.
      Choose the appropriate tool for tasks.

    # Tool execution notifications
    tool_notifications:
      enabled: true
      show_args: true
      icon: "ðŸ”§"
      format: "{icon} Executing tool: {tool_name}"
      # Available placeholders: {icon}, {tool_name}, {tool_args}

    # Logging configuration for chat service
    logging:
      tool_execution: true
      tool_results: true
      result_truncate_length: 200

# LLM Configuration - Just change the 'active' provider!
llm:
  active: "openai"  # Change this to: openai, groq, openrouter, anthropic, azure

  # Provider presets
  providers:
    openai:
      base_url: "https://api.openai.com/v1"
      model: "gpt-4o-mini"  # or gpt-4, gpt-4-turbo, etc.
      temperature: 0.7
      max_tokens: 4096
      top_p: 1.0

    groq:
      base_url: "https://api.groq.com/openai/v1"
      model: "llama-3.3-70b-versatile"  # or llama-3.1-8b-instant, etc.
      temperature: 0.7
      max_tokens: 4096
      top_p: 1.0

    openrouter:
      base_url: "https://openrouter.ai/api/v1"
      model: "anthropic/claude-3-sonnet"  # or other available models
      temperature: 0.7
      max_tokens: 4096
      top_p: 1.0

    anthropic:
      base_url: "https://api.anthropic.com/v1"
      model: "claude-3-sonnet-20240229"  # or claude-3-5-sonnet-latest, etc.
      temperature: 0.7
      max_tokens: 4096
      top_p: 1.0

    azure:
      base_url: "https://your-resource.openai.azure.com/openai/deployments/your-deployment"
      model: "gpt-4"  # matches your Azure deployment
      temperature: 0.7
      max_tokens: 4096
      top_p: 1.0
      api_version: "2024-02-15-preview"

# Logging Configuration
logging:
  level: "INFO"
  format: "%(asctime)s - %(levelname)s - %(message)s"

# MCP Server Configuration
mcp:
  config_file: "servers_config.json"
